{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f32063",
   "metadata": {},
   "source": [
    "# Hadoop TP1 - Initiation à Hadoop\n",
    "\n",
    "## Objectif\n",
    "Dans ce TP, nous allons configurer et interagir avec un cluster Apache Hadoop 3, en mettant l'accent sur HDFS (Hadoop Distributed File System)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b15d437",
   "metadata": {},
   "source": [
    "## Section 1 : Installation et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a4fd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/big-data-europe/docker-hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd docker-hadoop && docker-compose up -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6644fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3486eb7f",
   "metadata": {},
   "source": [
    "## Section 2 : Commandes HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc780291",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec -it namenode bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b09872",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"Bonjour Hadoop et HDFS\" > bonjour.txt\n",
    "!hdfs dfs -put bonjour.txt /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ccb3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls /\n",
    "!hdfs dfs -mkdir /data\n",
    "!hdfs dfs -put bonjour.txt /data\n",
    "!hdfs dfs -cat /data/bonjour.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10840ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -chmod go+w /data/bonjour.txt\n",
    "!hdfs dfs -mv /data/bonjour.txt /data/new_bonjour.txt\n",
    "!hdfs dfs -rm /data/new_bonjour.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781a3dce",
   "metadata": {},
   "source": [
    "## Section 3 : Création de Structure de Répertoires et Téléchargement de Fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0224dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -mkdir -p /TPs/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b483d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O purchases.txt https://bitly.ws/WTK8\n",
    "!hdfs dfs -put purchases.txt /TPs/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891e7cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O les_miserables.txt https://bitly.ws/WTKU\n",
    "!hdfs dfs -put les_miserables.txt /TPs/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf35ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls /TPs/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2b3edf",
   "metadata": {},
   "source": [
    "## Section 4 : Interface Web du Cluster\n",
    "naviguer vers http://localhost:9870/explorer.html#/ pour explorer l'interface Web Hadoop.\n",
    "Consultez les pages suivantes :\n",
    "- Aperçu : Vue de l'utilisation du stockage et de la capacité disponible.\n",
    "- Datanodes : Surveillance de la santé et de l'activité des datanodes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
